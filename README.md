# AI Detection Suite

A comprehensive multi-model platform for detecting fake news, AI-generated images, and analyzing website credibility using machine learning and AI.

## ğŸ¯ Features

### 1. **Fake News Detection** (Powered by Groq AI)
- Analyzes news articles for misinformation
- Uses Groq's llama-3.3-70b-versatile model
- Provides detailed verdict, confidence score, reasoning, and red flags
- High-performance AI inference
- Secure API key configuration via environment variables
- **Note:** Training data may not be up-to-date; quick web search recommended for recent events

### 2. **Website Credibility Analysis**
- Evaluates website trustworthiness using 67 features
- 85% accuracy with Extra Trees Classifier
- Automatic metadata extraction from URLs
- Batch analysis support

### 3. **AI Image Detection**
- Identifies AI-generated vs. authentic images
- ResNet50-based deep learning model
- Detects synthetic patterns and artifacts

## ğŸ“ Project Structure

```
AI-Detection-Suite/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ runtime.txt                 # Python version (3.11.9)
â”œâ”€â”€ packages.txt                # System packages for deployment
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ DEPLOYMENT.md          # Deployment guide
â”‚   â””â”€â”€ GROQ_SETUP.md          # Groq API setup instructions
â”‚
â”œâ”€â”€ models/                     # Machine learning models
â”‚   â”œâ”€â”€ stacking_model.joblib  # Website credibility model
â”‚   â”œâ”€â”€ feature_names.joblib   # Feature names for ML model
â”‚   â”œâ”€â”€ model_metadata.json    # Model metadata
â”‚   â”œâ”€â”€ resnet50_best_FIXED.keras  # Image detection model
â”‚   â”œâ”€â”€ config.joblib          # Model configuration
â”‚   â””â”€â”€ tokenizer.joblib       # Tokenizer (legacy)
â”‚
â”œâ”€â”€ data/                       # Data files
â”‚   â”œâ”€â”€ trusted_sources_original.csv
â”‚   â”œâ”€â”€ untrusted_sources.csv
â”‚   â””â”€â”€ website_metadata_examples.csv
â”‚
â”œâ”€â”€ utils/                      # Utility modules
â”‚   â”œâ”€â”€ webscraper.py          # Website metadata scraper
â”‚   â”œâ”€â”€ check_features.py      # Feature checking utilities
â”‚   â”œâ”€â”€ debug_features.py      # Debugging tools
â”‚   â””â”€â”€ analyze_trusted.py     # Data analysis scripts
â”‚
â”œâ”€â”€ tests/                      # Test files
â”‚   â”œâ”€â”€ test_model_bias.py     # Model bias tests
â”‚   â””â”€â”€ test_whois.py          # WHOIS functionality tests
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â””â”€â”€ modelling_realistic.ipynb  # Model development notebook
â”‚
â”œâ”€â”€ archive/                    # Archived datasets
â”‚   â”œâ”€â”€ README
â”‚   â””â”€â”€ *.tsv
â”‚
â””â”€â”€ saved_models/               # Backup/alternative models
    â””â”€â”€ (model backups)
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Get Groq API Key
1. Visit: https://console.groq.com/
2. Sign up or sign in
3. Create an API key
4. Copy the key

### 3. Set Environment Variable

**For Production (Streamlit Cloud):**
- Add to Streamlit Secrets:
  ```toml
  GROQ_API_KEY = "your-groq-api-key-here"
  ```

**For Local Development:**
```bash
# Create .env file
GROQ_API_KEY=your_groq_api_key_here

# Or set in terminal
export GROQ_API_KEY="your-groq-api-key-here"
```

### 4. Run the App
```bash
streamlit run app.py
```

### 5. Start Analyzing
- Check sidebar for "Groq API Status: Connected"
- Navigate to News Analysis tab
- Start analyzing news, websites, and images!

## ğŸ“Š Model Performance

### Website Credibility Model
- **Accuracy:** 85.00%
- **F1-Score:** 0.8370
- **Type:** Stacking Ensemble (Extra Trees)
- **Features:** 67 engineered features

### AI Image Detection Model
- **Architecture:** ResNet50
- **Input:** 224x224 RGB images
- **Classes:** Real vs. AI-generated

### Fake News Detection (Gemini AI)
- **Model:** Gemini 2.0 Flash Lite
- **Speed:** 2-5 seconds per analysis
- **Free Tier:** 60 req/min, 1,500 req/day

## ğŸ”§ Configuration Files

- **requirements.txt** - Python package dependencies
- **runtime.txt** - Python version specification (3.11.9)
- **packages.txt** - System-level packages for Streamlit Cloud
- **.gitignore** - Excludes large model files and cache

## ğŸ“š Documentation

- [Deployment Guide](docs/DEPLOYMENT.md) - Complete deployment instructions
- [Gemini Setup](docs/GEMINI_SETUP.md) - API key setup and troubleshooting

## ğŸŒ Deployment

### Streamlit Cloud (Recommended)
1. Push to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect repository
4. Deploy `app.py`

See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for detailed instructions.

## ğŸ› ï¸ Utility Scripts

Located in `utils/`:
- **webscraper.py** - Extracts metadata from URLs
- **check_features.py** - Validates feature engineering
- **debug_features.py** - Debugging model inputs
- **analyze_trusted.py** - Analyzes trusted source patterns

## ğŸ§ª Testing

Run tests from the `tests/` directory:
```bash
python tests/test_model_bias.py
python tests/test_whois.py
```

## ğŸ“¦ Dependencies

### Core
- streamlit >= 1.28.0
- numpy == 1.26.4
- scikit-learn == 1.5.2
- pandas == 2.2.3

### Deep Learning
- keras == 3.3.3
- tensorflow == 2.15.1

### AI API
- google-generativeai >= 0.3.0

### Web Scraping
- requests >= 2.31.0
- beautifulsoup4 >= 4.12.0
- python-whois >= 0.8.0

## ğŸ” Security

- **API Keys:** Never commit to Git
- **Use:** Streamlit Secrets or environment variables
- **Rotate:** Keys periodically
- **Monitor:** Usage in Google Cloud Console

## ğŸ“ License

This project is for educational and research purposes.

## ğŸ‘¥ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“ Support

For issues or questions:
1. Check [docs/GEMINI_SETUP.md](docs/GEMINI_SETUP.md) for API troubleshooting
2. Review [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for deployment issues
3. Open an issue on GitHub

## ğŸ¯ Roadmap

- [ ] Add more AI detection models
- [ ] Implement user authentication
- [ ] Add result export functionality
- [ ] Create REST API endpoints
- [ ] Add multi-language support

---

**Built with â¤ï¸ using Streamlit, TensorFlow, and Google Gemini AI**

Version: 2.0 | Last Updated: February 2026
